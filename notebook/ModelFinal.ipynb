{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36630e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#√âtape 1 : Chargement et nettoyage des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e929412e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chargement termin√© : (307511, 122) (48744, 121)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_path = \"C:/Users/fbe/Desktop/Bloc 4/application_train.csv\"\n",
    "test_path = \"C:/Users/fbe/Desktop/Bloc 4/application_test.csv\"\n",
    "\n",
    "# --- Chargement ---\n",
    "dt1 = pd.read_csv(train_path, sep=\";\", low_memory=False)\n",
    "test = pd.read_csv(test_path, sep=\";\", low_memory=False)\n",
    "print(\" Chargement termin√© :\", dt1.shape, test.shape)\n",
    "\n",
    "# Nettoyage valeur aberrante\n",
    "dt1[\"DAYS_EMPLOYED\"] = dt1[\"DAYS_EMPLOYED\"].replace(365243, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83f8cbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SK_ID_CURR', 'TARGET', 'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'ORGANIZATION_TYPE', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', 'TOTALAREA_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']\n"
     ]
    }
   ],
   "source": [
    "print(dt1.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "285adba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGPD - Minimisation des donn√©es\n",
    "# Seules les variables n√©cessaires √† l‚Äô√©valuation du risque de cr√©dit sont conserv√©es.\n",
    "# Aucune donn√©e personnelle directement identifiable (nom, adresse, t√©l√©phone, email, etc.) n‚Äôest utilis√©e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7142bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Variables retenues : 20\n"
     ]
    }
   ],
   "source": [
    "cols_utiles = [\n",
    "    'SK_ID_CURR',\n",
    "    'CODE_GENDER', 'NAME_FAMILY_STATUS', 'NAME_EDUCATION_TYPE',\n",
    "    'OCCUPATION_TYPE', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
    "    'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE',\n",
    "    'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH',\n",
    "    'CNT_CHILDREN', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'TARGET'\n",
    "]\n",
    "\n",
    "\n",
    "data = dt1[cols_utiles].copy()\n",
    "print(\" Variables retenues :\", len(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c189f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables retenues : 20 colonnes -> ['SK_ID_CURR', 'CODE_GENDER', 'NAME_FAMILY_STATUS', 'NAME_EDUCATION_TYPE', 'OCCUPATION_TYPE', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'CNT_CHILDREN', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'TARGET']\n"
     ]
    }
   ],
   "source": [
    "# Garder uniquement les colonnes n√©cessaires \n",
    "data = dt1[ [c for c in cols_utiles if c in dt1.columns] ].copy()\n",
    "print(\"Variables retenues :\", data.shape[1], \"colonnes ->\", data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eaa197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Colonnes corrig√©es (abs) : ['DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_ID_PUBLISH']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307511 entries, 0 to 307510\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   DAYS_BIRTH       307511 non-null  int64  \n",
      " 1   DAYS_EMPLOYED    252137 non-null  float64\n",
      " 2   DAYS_ID_PUBLISH  307511 non-null  int64  \n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 7.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# - Identifier colonnes num√©riques enti√®rement n√©gatives\n",
    "# ============================\n",
    "col_neg = [\n",
    "    col for col in data.select_dtypes(include=np.number).columns\n",
    "    if (data[col].dropna() <= 0).all()\n",
    "]\n",
    "\n",
    "if col_neg:\n",
    "    data_abs = data[col_neg].copy().abs()   # appliquer la valeur absolue\n",
    "    data = data.drop(columns=col_neg)\n",
    "    data = pd.concat([data_abs, data], axis=1)\n",
    "    print(f\" Colonnes corrig√©es (abs) : {col_neg}\")\n",
    "    print(data_abs.info())\n",
    "else:\n",
    "    print(\" Aucune colonne enti√®rement n√©gative d√©tect√©e.\")\n",
    "\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caecca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Colonne AMT_ANNUITY a 12 valeurs non convertibles\n",
      "‚ö†Ô∏è Colonne AMT_GOODS_PRICE a 278 valeurs non convertibles\n",
      "‚ö†Ô∏è Colonne DAYS_EMPLOYED a 55374 valeurs non convertibles\n",
      "‚ö†Ô∏è Colonne EXT_SOURCE_1 a 173378 valeurs non convertibles\n",
      "‚ö†Ô∏è Colonne EXT_SOURCE_2 a 660 valeurs non convertibles\n",
      "‚ö†Ô∏è Colonne EXT_SOURCE_3 a 60965 valeurs non convertibles\n",
      "‚úÖ NaN remplis : cat√©gorielles -> 'Unknown', num√©riques -> moyennes\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "#  D√©finition des colonnes num√©riques et cat√©gorielles\n",
    "# ============================\n",
    "\n",
    "cat_cols = [\n",
    "    'CODE_GENDER', 'NAME_FAMILY_STATUS', 'NAME_EDUCATION_TYPE',\n",
    "    'OCCUPATION_TYPE', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY'\n",
    "]\n",
    "\n",
    "num_cols = [\n",
    "    'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE',\n",
    "    'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH',\n",
    "    'CNT_CHILDREN', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3'\n",
    "]\n",
    "\n",
    "# ============================\n",
    "#  Nettoyage complet des nombres \n",
    "# ============================\n",
    "\n",
    "for c in num_cols:\n",
    "    if c in data.columns:\n",
    "        # Remplacer virgule par point\n",
    "        data[c] = data[c].astype(str).str.replace(\",\", \".\", regex=False)\n",
    "        # Supprimer tout sauf chiffres, point, signe moins et exposants\n",
    "        data[c] = data[c].str.replace(r\"[^0-9\\.\\-eE]\", \"\", regex=True)\n",
    "        # Convertir en float (NaN si conversion impossible)\n",
    "        data[c] = pd.to_numeric(data[c], errors='coerce')\n",
    "\n",
    "# ============================\n",
    "#  V√©rification rapide des valeurs encore non convertibles\n",
    "# ============================\n",
    "\n",
    "for c in num_cols:\n",
    "    non_convertibles = data[c][data[c].isna()]\n",
    "    if len(non_convertibles) > 0:\n",
    "        print(f\" Colonne {c} a {len(non_convertibles)} valeurs non convertibles\")\n",
    "\n",
    "# ============================\n",
    "#  - Gestion des NaN\n",
    "# ============================\n",
    "\n",
    "data[cat_cols] = data[cat_cols].fillna(\"Unknown\")\n",
    "data[num_cols] = data[num_cols].fillna(data[num_cols].mean())\n",
    "\n",
    "print(\" NaN remplis : cat√©gorielles -> 'Unknown', num√©riques -> moyennes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b1dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Encodage termin√©.\n",
      "üß© Dimensions finales : (307511, 43)\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# ============================\n",
    "#  - Encodage One-Hot\n",
    "# ============================\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    drop='first',\n",
    "    sparse_output=True,\n",
    "    handle_unknown='ignore'\n",
    ")\n",
    "\n",
    "X_cat = encoder.fit_transform(data[cat_cols])\n",
    "\n",
    "# ============================\n",
    "# - Pr√©paration des colonnes num√©riques\n",
    "# ============================\n",
    "\n",
    "\n",
    "for c in num_cols:\n",
    "    data[c] = pd.to_numeric(data[c], errors='coerce')\n",
    "\n",
    "# Remplir les NaN avec la moyenne\n",
    "X_num = data[num_cols].fillna(data[num_cols].mean())\n",
    "X_num_sparse = scipy.sparse.csr_matrix(X_num.to_numpy())\n",
    "\n",
    "# ============================\n",
    "#  - Fusion finale des donn√©es\n",
    "# ============================\n",
    "\n",
    "X_final = scipy.sparse.hstack([X_num_sparse, X_cat])\n",
    "y = data['TARGET']\n",
    "\n",
    "print(\" Encodage termin√©.\")\n",
    "print(\" Dimensions finales :\", X_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d4f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Split effectu√© : (246008, 43) (61503, 43)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_final, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "print(\" Split effectu√© :\", X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe5f428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant SMOTE : {0: 226148, 1: 19860}\n",
      "Apr√®s SMOTE  : {0: 226148, 1: 226148}\n",
      "‚úÖ Jeu d'entra√Ænement √©quilibr√© : (452296, 43)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Cr√©ation du sur√©chantillonneur\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Application uniquement sur les donn√©es d‚Äôentra√Ænement\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Avant SMOTE :\", y_train.value_counts().to_dict())\n",
    "print(\"Apr√®s SMOTE  :\", y_res.value_counts().to_dict())\n",
    "print(\" Jeu d'entra√Ænement √©quilibr√© :\", X_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17154c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ AUC sur le test set : 0.755\n",
      "\n",
      "üìä Matrice de confusion :\n",
      " [[55505  1033]\n",
      " [ 4316   649]]\n",
      "\n",
      "üìÑ Rapport de classification :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95     56538\n",
      "           1       0.39      0.13      0.20      4965\n",
      "\n",
      "    accuracy                           0.91     61503\n",
      "   macro avg       0.66      0.56      0.57     61503\n",
      "weighted avg       0.88      0.91      0.89     61503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "# Entra√Ænement avec les donn√©es √©quilibr√©es\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric='auc',\n",
    "    tree_method='hist',\n",
    "    random_state=42,\n",
    "    n_jobs=4\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_res, y_res)\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "# Probabilit√©s (classe \"1\")\n",
    "y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#  AUC ‚Äî ne d√©pend pas du seuil\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\" AUC sur le test set : {auc:.3f}\")\n",
    "\n",
    "#  Application du seuil personnalis√©\n",
    "threshold = 0.3  # plus sensible pour d√©tecter les \"1\"\n",
    "y_pred_class = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "#  Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred_class)\n",
    "print(\"\\n Matrice de confusion :\\n\", cm)\n",
    "\n",
    "#  Rapport de classification\n",
    "cr = classification_report(y_test, y_pred_class)\n",
    "print(\"\\n Rapport de classification :\\n\", cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40e17ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SK_ID_CURR  Score_Eligibilite Prediction\n",
      "256571      396899           0.060965        Yes\n",
      "191493      322041           0.058236        Yes\n",
      "103497      220127           0.332005         No\n",
      "130646      251531           0.039546        Yes\n",
      "211898      345558           0.103620        Yes\n",
      "‚úÖ Fichier export√© : C:/Users/fbe/Desktop/Bloc 4/dashboard_eligibilite2.csv\n"
     ]
    }
   ],
   "source": [
    "# Cr√©ation du dashboard interne\n",
    "# ============================\n",
    "# \"Yes\" = √©ligible au cr√©dit\n",
    "y_pred_class_labels = np.where(y_pred_class == 0, \"Yes\", \"No\")\n",
    "\n",
    "dashboard_df = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": dt1.loc[y_test.index, 'SK_ID_CURR'],\n",
    "    \"Score_Eligibilite\": y_pred_proba,\n",
    "    \"Prediction\": y_pred_class_labels\n",
    "})\n",
    "\n",
    "print(dashboard_df.head())\n",
    "\n",
    "\n",
    "cat_cols = [\n",
    "    'CODE_GENDER', 'NAME_FAMILY_STATUS', 'NAME_EDUCATION_TYPE',\n",
    "    'OCCUPATION_TYPE', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY'\n",
    "]\n",
    "\n",
    "num_cols = [\n",
    "    'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE',\n",
    "    'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH',\n",
    "    'CNT_CHILDREN', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3'\n",
    "]\n",
    "\n",
    "\n",
    "all_cols = cat_cols + num_cols\n",
    "missing_cols = [c for c in all_cols if c not in data.columns]\n",
    "if missing_cols:\n",
    "    print(f\" Colonnes manquantes dans 'data' : {missing_cols}\")\n",
    "\n",
    "\n",
    "cols_to_add = [c for c in all_cols if c in data.columns]\n",
    "dashboard_df = pd.concat([dashboard_df, data.loc[y_test.index, cols_to_add]], axis=1)\n",
    "\n",
    "#  Sauvegarde CSV\n",
    "output_path = \"C:/Users/fbe/Desktop/Bloc 4/dashboard_eligibilite2.csv\"\n",
    "dashboard_df.to_csv(output_path, sep=\";\", index=False)\n",
    "print(f\" Fichier export√© : {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482337b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mod√®le XGBoost, encodeur et colonnes sauvegard√©s avec succ√®s !\n",
      "üìä Nombre total de colonnes : 43\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "encoded_cols = encoder.get_feature_names_out(cat_cols)\n",
    "all_final_cols = list(num_cols) + list(encoded_cols)\n",
    "\n",
    "#  Sauvegarde du mod√®le\n",
    "joblib.dump(xgb_model, \"modele_xgboost_eligibilite_credit.pkl\")\n",
    "joblib.dump(encoder, \"encodeur_variables_categorielles.pkl\")\n",
    "joblib.dump(all_final_cols, \"colonnes_modele.pkl\")\n",
    "\n",
    "print(f\" Mod√®le XGBoost, encodeur et colonnes sauvegard√©s avec succ√®s !\")\n",
    "print(f\" Nombre total de colonnes : {len(all_final_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a4c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52e50423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 colonnes attendues :\n",
      "['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'CNT_CHILDREN', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'CODE_GENDER_M', 'CODE_GENDER_XNA', 'NAME_FAMILY_STATUS_Married', 'NAME_FAMILY_STATUS_Separated', 'NAME_FAMILY_STATUS_Single / not married', 'NAME_FAMILY_STATUS_Unknown', 'NAME_FAMILY_STATUS_Widow', 'NAME_EDUCATION_TYPE_Higher education', 'NAME_EDUCATION_TYPE_Incomplete higher', 'NAME_EDUCATION_TYPE_Lower secondary', 'NAME_EDUCATION_TYPE_Secondary / secondary special', 'OCCUPATION_TYPE_Cleaning staff', 'OCCUPATION_TYPE_Cooking staff', 'OCCUPATION_TYPE_Core staff', 'OCCUPATION_TYPE_Drivers', 'OCCUPATION_TYPE_HR staff', 'OCCUPATION_TYPE_High skill tech staff', 'OCCUPATION_TYPE_IT staff', 'OCCUPATION_TYPE_Laborers', 'OCCUPATION_TYPE_Low-skill Laborers', 'OCCUPATION_TYPE_Managers', 'OCCUPATION_TYPE_Medicine staff', 'OCCUPATION_TYPE_Private service staff', 'OCCUPATION_TYPE_Realty agents', 'OCCUPATION_TYPE_Sales staff', 'OCCUPATION_TYPE_Secretaries', 'OCCUPATION_TYPE_Security staff', 'OCCUPATION_TYPE_Unknown', 'OCCUPATION_TYPE_Waiters/barmen staff', 'FLAG_OWN_CAR_Y', 'FLAG_OWN_REALTY_Y']\n"
     ]
    }
   ],
   "source": [
    "cols = joblib.load(\"colonnes_modele.pkl\")\n",
    "print(len(cols), \"colonnes attendues :\")\n",
    "print(cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
